name: Lighthouse CI

on:
  schedule:
    - cron: "0 8 * * *" # Run every day at 8 AM
    - cron: "0 18 * * *" # Run every day at 6 PM
  # Allow manual trigger through GitHub UI
  workflow_dispatch:

# Allow cancellation of previous runs in the same PR/branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write
  pull-requests: write
  pages: write
  id-token: write

# Define environment for GitHub Pages
env:
  HISTORY_BRANCH: lighthouse-history

jobs:
  lighthouse-ci:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    strategy:
      matrix:
        page:
          - name: homepage
            url: https://curalife.com/
          - name: product
            url: https://curalife.com/products/curalin
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "18"

      - name: Install dependencies
        run: |
          npm install -g @lhci/cli puppeteer lighthouse puppeteer-screenshot-cli

      - name: Set Chrome flags
        run: |
          echo "CHROME_FLAGS=--no-sandbox --disable-dev-shm-usage --disable-gpu --headless" >> $GITHUB_ENV

      - name: Setup results directory
        id: results-dir
        run: |
          RESULTS_DIR="${{ matrix.page.name }}-lighthouse-results"
          echo "results_dir=$RESULTS_DIR" >> $GITHUB_OUTPUT
          mkdir -p $RESULTS_DIR

      - name: Make scripts executable
        run: |
          chmod +x .github/workflows/scripts/make-scripts-executable.sh
          .github/workflows/scripts/make-scripts-executable.sh

      - name: Run Lighthouse CI
        id: lighthouse
        run: |
          echo "Running Lighthouse on ${{ matrix.page.url }}..."
          .github/workflows/scripts/run-lighthouse.sh "${{ matrix.page.url }}" "${{ matrix.page.name }}" "${{ steps.results-dir.outputs.results_dir }}"
        continue-on-error: true

      - name: Install jq for results processing
        run: sudo apt-get update && sudo apt-get install -y jq bc

      - name: Process Lighthouse results
        id: scores
        run: |
          # Set current date for outputs
          CURRENT_DATE=$(date +"%Y-%m-%d")
          echo "report_date=$CURRENT_DATE" >> $GITHUB_OUTPUT

          .github/workflows/scripts/process-results.sh "${{ matrix.page.name }}" "${{ steps.results-dir.outputs.results_dir }}" "$CURRENT_DATE"
        continue-on-error: true

      - name: Save reports to performance-reports directory
        if: steps.scores.outputs.has_results == 'true'
        run: |
          .github/workflows/scripts/save-reports.sh "${{ matrix.page.name }}" "${{ steps.results-dir.outputs.results_dir }}" "${{ steps.scores.outputs.report_date }}"
        continue-on-error: true

      - name: Format Lighthouse results
        if: steps.scores.outputs.has_results == 'true'
        run: |
          .github/workflows/scripts/format-summary.sh "${{ matrix.page.name }}"
        continue-on-error: true

      # Upload results for this page as an artifact
      - name: Upload individual page report
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.page.name }}-lighthouse-report
          path: performance-reports/
          retention-days: 30
        continue-on-error: true

    outputs:
      report_date: ${{ steps.scores.outputs.report_date }}

  create-dashboard:
    needs: lighthouse-ci
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Make scripts executable
        run: |
          chmod +x .github/workflows/scripts/make-scripts-executable.sh
          .github/workflows/scripts/make-scripts-executable.sh

      - name: Create performance-reports directory
        run: mkdir -p performance-reports

      # Download all page reports to combine them
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-reports-downloads
          pattern: "*-lighthouse-report"
          merge-multiple: true
        continue-on-error: true

      # Copy all downloaded artifacts to the performance-reports directory
      - name: Organize reports
        run: |
          echo "Listing downloaded artifacts:"
          ls -la performance-reports-downloads || echo "No downloads directory found"

          # Create the performance reports directory if it doesn't exist
          mkdir -p performance-reports

          # Only try to copy if the downloads directory exists and has files
          if [ -d "performance-reports-downloads" ] && [ "$(ls -A performance-reports-downloads 2>/dev/null)" ]; then
            echo "Copying artifacts to performance-reports directory"
            cp -R performance-reports-downloads/* performance-reports/ || echo "No files to copy"
          else
            echo "No artifacts found to copy"
            # Create sample data with a simple approach instead of heredoc
            mkdir -p performance-reports/$(date +"%Y-%m-%d")/sample
            CURRENT_DATE=$(date +"%Y-%m-%d")

            echo "Creating sample data file at performance-reports/$CURRENT_DATE/sample/summary.json"
            echo '{
              "page": "sample",
              "url": "https://example.com",
              "date": "'$CURRENT_DATE'",
              "desktop": {
                "performance": 90,
                "accessibility": 90,
                "bestPractices": 90,
                "seo": 90,
                "pwa": 90,
                "metrics": {
                  "firstContentfulPaint": 1000,
                  "speedIndex": 1500,
                  "largestContentfulPaint": 2000,
                  "timeToInteractive": 2500,
                  "totalBlockingTime": 100,
                  "maxPotentialFID": 100,
                  "cumulativeLayoutShift": 0.05
                },
                "opportunities": {
                  "renderBlockingResources": 0,
                  "unusedCSSBytes": 0,
                  "unusedJSBytes": 0,
                  "offscreenImagesBytes": 0,
                  "totalBytes": 500000,
                  "domSize": 1000
                }
              },
              "mobile": {
                "performance": 85,
                "accessibility": 90,
                "bestPractices": 90,
                "seo": 90,
                "pwa": 90,
                "metrics": {
                  "firstContentfulPaint": 1200,
                  "speedIndex": 1800,
                  "largestContentfulPaint": 2400,
                  "timeToInteractive": 3000,
                  "totalBlockingTime": 150,
                  "maxPotentialFID": 150,
                  "cumulativeLayoutShift": 0.08
                },
                "opportunities": {
                  "renderBlockingResources": 0,
                  "unusedCSSBytes": 0,
                  "unusedJSBytes": 0,
                  "offscreenImagesBytes": 0,
                  "totalBytes": 600000,
                  "domSize": 1000
                }
              }
            }' > performance-reports/$CURRENT_DATE/sample/summary.json
          fi

          # Check if there are any files in the performance-reports directory
          echo "Contents of performance-reports directory:"
          find performance-reports -type f | sort || echo "No files found in performance-reports"

      # Fetch historical data from the dedicated branch
      - name: Fetch historical data
        id: fetch-history
        run: |
          CURRENT_DATE="${{ needs.lighthouse-ci.outputs.report_date }}"
          if [ -z "$CURRENT_DATE" ]; then
            CURRENT_DATE=$(date +"%Y-%m-%d")
          fi
          echo "report_date=$CURRENT_DATE" >> $GITHUB_OUTPUT

          # Check if history branch exists
          if git fetch --all && git ls-remote --heads origin ${{ env.HISTORY_BRANCH }} | grep ${{ env.HISTORY_BRANCH }}; then
            echo "History branch exists, fetching data..."
            git checkout ${{ env.HISTORY_BRANCH }} || git checkout -b ${{ env.HISTORY_BRANCH }}
            # Create history directory if it doesn't exist
            mkdir -p performance-reports/history

            # Move back to the original branch to continue workflow
            git checkout -
            # Copy history data to the current workspace
            if [ -d ".git/refs/remotes/origin/${{ env.HISTORY_BRANCH }}" ]; then
              git checkout ${{ env.HISTORY_BRANCH }} -- performance-reports/history || echo "No history data found"
              git checkout - || echo "Failed to checkout previous branch"
            fi
          else
            echo "History branch does not exist, creating it..."
            git checkout -b ${{ env.HISTORY_BRANCH }} || echo "Failed to create history branch"
            mkdir -p performance-reports/history
            git checkout - || echo "Failed to checkout previous branch"
          fi

          # Make sure the history directory exists
          mkdir -p performance-reports/history

      # Process historical data
      - name: Process historical data
        run: |
          # Make the script executable
          chmod +x .github/workflows/scripts/store-historical-data.sh

          # Run the script to process data
          .github/workflows/scripts/store-historical-data.sh "${{ steps.fetch-history.outputs.report_date }}"
        continue-on-error: true

      # Generate the trend dashboard
      - name: Generate trend dashboard
        run: |
          # Make the script executable
          chmod +x .github/workflows/scripts/generate-trend-dashboard.sh

          # Run the script to generate the dashboard
          .github/workflows/scripts/generate-trend-dashboard.sh "${{ steps.fetch-history.outputs.report_date }}"
        continue-on-error: true

      # Generate the HTML dashboard - split into smaller steps for better error tracking
      - name: Generate HTML dashboard
        run: |
          CURRENT_DATE="${{ steps.fetch-history.outputs.report_date }}"
          if [ -z "$CURRENT_DATE" ]; then
            CURRENT_DATE=$(date +"%Y-%m-%d")
          fi

          echo "Generating dashboard for date: $CURRENT_DATE"

          # Ensure the directory exists
          mkdir -p performance-reports

          # Run with bash -e to exit immediately on error
          bash -e .github/workflows/scripts/generate-dashboard.sh "$CURRENT_DATE" || {
            echo "Error generating dashboard, creating fallback..."
            # Create a simple default dashboard if the script fails
            echo '<!DOCTYPE html><html><head><title>Lighthouse Dashboard</title><style>body{font-family:Arial,sans-serif;margin:40px}.container{max-width:800px;margin:0 auto}h1{color:#333}.error{color:#d32f2f}</style></head><body><div class="container"><h1>Lighthouse Dashboard</h1><p class="error">No valid reports were found or an error occurred during dashboard generation.</p><p>Please check the workflow logs for more details.</p></div></body></html>' > performance-reports/index.html
            echo "Created fallback dashboard"
          }

          echo "Dashboard file generation complete"

          # Verify the files exist and are readable
          if [ -f "performance-reports/index.html" ]; then
            echo "Dashboard file exists at performance-reports/index.html"
            ls -la performance-reports/index.html
            echo "File contents:"
            head -n 5 performance-reports/index.html
          else
            echo "Error: Dashboard file was not created!"
            exit 1
          fi

          # Add link to trends dashboard on main dashboard page
          if [ -f "performance-reports/index.html" ] && [ -f "performance-reports/trends.html" ]; then
            echo "Adding trends dashboard link..."
            sed -i 's/<\/body>/<div style="text-align: center; margin-top: 30px;"><a href="trends.html" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-decoration: none; border-radius: 4px; font-weight: bold;">View Performance Trends Over Time<\/a><\/div><\/body>/' performance-reports/index.html
            echo "Trends dashboard link added"
          else
            echo "Warning: trends.html not found, skipping link addition"
          fi

          # Final verification
          echo "Final directory contents:"
          ls -la performance-reports/

      # Generate the GitHub Step Summary separately for better error handling
      - name: Generate GitHub Step Summary
        run: |
          # Create a basic step summary header
          echo "## üö¶ Lighthouse Performance Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Summary Results ($(date))" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check if there are any summary files to process
          SUMMARY_FILES=$(find performance-reports -name "summary.json" | wc -l)

          if [ "$SUMMARY_FILES" -eq "0" ]; then
            echo "No summary files found to process" >> $GITHUB_STEP_SUMMARY
            echo "No test results are available for this run." >> $GITHUB_STEP_SUMMARY
          else
            echo "Found $SUMMARY_FILES summary files to process"

            # Add a table for desktop results
            echo "#### üíª Desktop Results" >> $GITHUB_STEP_SUMMARY
            echo "| Page | Performance | Accessibility | Best Practices | SEO | LCP | TBT | CLS |" >> $GITHUB_STEP_SUMMARY
            echo "|------|-------------|---------------|----------------|-----|-----|-----|-----|" >> $GITHUB_STEP_SUMMARY

            # Find all summary.json files for desktop
            find performance-reports -name "summary.json" | sort | while read -r file; do
              # Debug
              echo "Processing file: $file"

              # Extract data safely with error handling
              PAGE_NAME=$(grep -o '"page": *"[^"]*"' "$file" | cut -d'"' -f4 || echo "unknown")
              PERF=$(grep -o '"performance": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              A11Y=$(grep -o '"accessibility": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              BP=$(grep -o '"bestPractices": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              SEO=$(grep -o '"seo": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              LCP=$(grep -o '"largestContentfulPaint": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              TBT=$(grep -o '"totalBlockingTime": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              CLS=$(grep -o '"cumulativeLayoutShift": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")

              # Format values for display
              LCP_MS=$(echo "$LCP / 1000" | bc -l 2>/dev/null | xargs printf "%.2fs" 2>/dev/null || echo "0.00s")
              TBT_MS=$(echo "$TBT" | xargs printf "%.0fms" 2>/dev/null || echo "0ms")

              echo "| $PAGE_NAME | $PERF | $A11Y | $BP | $SEO | $LCP_MS | $TBT_MS | $CLS |" >> $GITHUB_STEP_SUMMARY
            done

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "#### üì± Mobile Results" >> $GITHUB_STEP_SUMMARY
            echo "| Page | Performance | Accessibility | Best Practices | SEO | LCP | TBT | CLS |" >> $GITHUB_STEP_SUMMARY
            echo "|------|-------------|---------------|----------------|-----|-----|-----|-----|" >> $GITHUB_STEP_SUMMARY

            # Find all summary.json files for mobile
            find performance-reports -name "summary.json" | sort | while read -r file; do
              # Extract data safely with error handling
              PAGE_NAME=$(grep -o '"page": *"[^"]*"' "$file" | cut -d'"' -f4 || echo "unknown")
              PERF=$(grep -o '"performance": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              A11Y=$(grep -o '"accessibility": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              BP=$(grep -o '"bestPractices": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              SEO=$(grep -o '"seo": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              LCP=$(grep -o '"largestContentfulPaint": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              TBT=$(grep -o '"totalBlockingTime": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")
              CLS=$(grep -o '"cumulativeLayoutShift": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")

              # Format values for display
              LCP_MS=$(echo "$LCP / 1000" | bc -l 2>/dev/null | xargs printf "%.2fs" 2>/dev/null || echo "0.00s")
              TBT_MS=$(echo "$TBT" | xargs printf "%.0fms" 2>/dev/null || echo "0ms")

              echo "| $PAGE_NAME | $PERF | $A11Y | $BP | $SEO | $LCP_MS | $TBT_MS | $CLS |" >> $GITHUB_STEP_SUMMARY
            done

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìà Core Web Vitals Status" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ **Good**: LCP < 2.5s, CLS < 0.1, TBT < 200ms" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ö†Ô∏è **Needs Improvement**: LCP < 4s, CLS < 0.25, TBT < 600ms" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ùå **Poor**: LCP > 4s, CLS > 0.25, TBT > 600ms" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîç View Full Reports" >> $GITHUB_STEP_SUMMARY
          echo "Download the full HTML reports from the workflow artifacts section." >> $GITHUB_STEP_SUMMARY

      # Link to the trends dashboard in the GitHub Step Summary
      - name: Add trends link to summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìà Performance Trends" >> $GITHUB_STEP_SUMMARY
          echo "Check out the [Performance Trends Dashboard](./trends.html) to see how metrics have changed over time." >> $GITHUB_STEP_SUMMARY

      - name: List created files
        run: |
          echo "Files created in performance-reports directory:"
          mkdir -p performance-reports
          find performance-reports -type f | sort || echo "No files found in performance-reports"

      # Upload the complete combined report
      - name: Upload performance reports
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-complete-report
          path: performance-reports/
          retention-days: 30
        continue-on-error: true

      # Verify files before uploading
      - name: Verify files before upload
        run: |
          echo "Verifying files before upload..."
          echo "Directory structure:"
          tree performance-reports || echo "tree command not available"
          echo "File contents:"
          ls -la performance-reports/
          echo "Checking index.html:"
          if [ -f "performance-reports/index.html" ]; then
            echo "index.html exists"
            head -n 5 performance-reports/index.html
          else
            echo "index.html does not exist!"
            exit 1
          fi
          echo "Checking trends.html:"
          if [ -f "performance-reports/trends.html" ]; then
            echo "trends.html exists"
            head -n 5 performance-reports/trends.html
          else
            echo "trends.html does not exist"
          fi

      # Generate visual annotations for PRs
      - name: Add PR annotations
        if: github.event_name == 'pull_request'
        run: |
          # Find all summary.json files
          find performance-reports -name "summary.json" | sort | while read -r file; do
            PAGE_NAME=$(grep -o '"page": *"[^"]*"' "$file" | cut -d'"' -f4 || echo "unknown")
            PERF=$(grep -o '"performance": *[0-9.]*' "$file" | grep -o '[0-9.]*' || echo "0")

            # Add annotations based on performance score
            if (( $(echo "$PERF < 75" | bc -l) )); then
              echo "::warning file=${PAGE_NAME}::Performance score is poor: ${PERF}%. Consider optimizing this page."
            elif (( $(echo "$PERF < 90" | bc -l) )); then
              echo "::notice file=${PAGE_NAME}::Performance score needs improvement: ${PERF}%."
            else
              echo "::notice file=${PAGE_NAME}::Performance score is good: ${PERF}%."
            fi
          done
        continue-on-error: true

      # Save historical data to the dedicated branch
      - name: Save historical data
        run: |
          # Configure Git
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"

          # Add and commit changes to history directory
          mkdir -p performance-reports/history
          if git checkout ${{ env.HISTORY_BRANCH }}; then
            # Copy current history to the branch
            mkdir -p performance-reports/history
            # Copy only if any history exists
            if [ -d "performance-reports/history" ] && [ "$(ls -A performance-reports/history 2>/dev/null)" ]; then
              git add performance-reports/history
              git commit -m "Update Lighthouse history data - $(date +%Y-%m-%d)" || echo "No changes to commit"
              git push origin ${{ env.HISTORY_BRANCH }} || echo "Failed to push - possibly no changes"
            fi
          else
            # Create new branch with history
            git checkout -b ${{ env.HISTORY_BRANCH }}
            mkdir -p performance-reports/history
            # Only commit if there are actual files
            if [ -d "performance-reports/history" ] && [ "$(ls -A performance-reports/history 2>/dev/null)" ]; then
              git add performance-reports/history
              git commit -m "Initial Lighthouse history data - $(date +%Y-%m-%d)" || echo "No changes to commit"
              git push origin ${{ env.HISTORY_BRANCH }} || echo "Failed to push - possibly no changes"
            fi
          fi
        continue-on-error: true

  # New job to deploy to GitHub Pages
  deploy-pages:
    needs: create-dashboard
    runs-on: ubuntu-latest
    # Only run on main/master branch to avoid duplicate deployments
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Download the performance reports
      - name: Download performance reports
        uses: actions/download-artifact@v4
        with:
          name: lighthouse-complete-report
          path: performance-reports

      # Verify downloaded files
      - name: Verify downloaded files
        run: |
          echo "Checking contents of performance-reports directory:"
          ls -la performance-reports || echo "Directory is empty"
          echo "Checking for index.html:"
          ls -la performance-reports/index.html || echo "index.html not found"
          echo "Checking for trends.html:"
          ls -la performance-reports/trends.html || echo "trends.html not found"

      # Setup GitHub Pages
      - name: Setup Pages
        uses: actions/configure-pages@v4
        with:
          enablement: true

      # Create a minimal index.html if it doesn't exist
      - name: Ensure index.html exists
        run: |
          if [ ! -f "performance-reports/index.html" ]; then
            echo "Creating minimal index.html..."
            mkdir -p performance-reports
            echo '<!DOCTYPE html><html><head><title>Lighthouse Dashboard</title><style>body{font-family:Arial,sans-serif;margin:40px}.container{max-width:800px;margin:0 auto}h1{color:#333}.error{color:#d32f2f}</style></head><body><div class="container"><h1>Lighthouse Dashboard</h1><p class="error">No valid reports were found or an error occurred during dashboard generation.</p><p>Please check the workflow logs for more details.</p></div></body></html>' > performance-reports/index.html
          fi

      # Upload pages artifact
      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: performance-reports
          retention-days: 1

      # Verify uploaded artifact
      - name: Verify uploaded artifact
        run: |
          echo "Verifying uploaded artifact..."
          if [ ! -f "performance-reports/index.html" ]; then
            echo "Error: index.html not found in performance-reports directory"
            exit 1
          fi
          echo "Artifact verification successful"

      # Deploy to GitHub Pages
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v3
